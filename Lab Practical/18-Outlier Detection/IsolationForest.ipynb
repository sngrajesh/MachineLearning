{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extra Trees Regressor** (Extremely Randomized Trees Regressor)\n",
    "\n",
    "The **Extra Trees Regressor** is an ensemble method in machine learning for regression tasks. It uses a collection of decision trees, where each tree is trained on the entire dataset, but with extra randomness introduced in tree construction.\n",
    "\n",
    "#### **How It Works**\n",
    "1. **Ensemble of Trees**:\n",
    "   - Similar to Random Forest, it aggregates predictions from multiple decision trees.\n",
    "   - Trees are built independently, and their predictions are averaged to produce the final output.\n",
    "\n",
    "2. **Random Splits**:\n",
    "   - Unlike Random Forest, which chooses the best split based on a criterion like Gini or MSE, Extra Trees randomly selects thresholds for splits.\n",
    "   - This increases diversity among the trees and reduces overfitting.\n",
    "\n",
    "3. **Bootstrapping**:\n",
    "   - Unlike Random Forest, Extra Trees typically use the entire dataset without bootstrapping (by default), although it can be enabled.\n",
    "\n",
    "#### **Key Features**\n",
    "- **Extra Randomness**: \n",
    "  - Both features and split thresholds are selected randomly.\n",
    "- **Bias-Variance Tradeoff**: \n",
    "  - Extra Trees focus on reducing variance by randomizing splits, often at the cost of slightly increased bias.\n",
    "\n",
    "#### **Advantages**\n",
    "- **Efficient Training**: Since splits are random, the algorithm is faster to train compared to Random Forest.\n",
    "- **Good Generalization**: Works well for high-dimensional data and reduces the risk of overfitting.\n",
    "- **Robust to Noise**: Handles noisy data effectively due to its randomness.\n",
    "\n",
    "#### **Disadvantages**\n",
    "- **Less Interpretability**: Increased randomness makes it harder to interpret compared to standard decision trees.\n",
    "- **Not Always Optimal**: May perform worse than Random Forest for some datasets where well-optimized splits are crucial.\n",
    "\n",
    "#### **Common Use Cases**\n",
    "- Predicting continuous values in tasks like:\n",
    "  - House price prediction\n",
    "  - Stock market analysis\n",
    "  - Energy consumption forecasting\n",
    "\n",
    "#### **Implementation in Python**\n",
    "Here’s an example of how to use **Extra Trees Regressor** with Scikit-Learn:\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load or generate data\n",
    "X, y = some_dataset()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Extra Trees Regressor\n",
    "et_regressor = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "et_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = et_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "```\n",
    "\n",
    "#### **Key Parameters**\n",
    "- `n_estimators`: Number of trees in the forest (default = 100).\n",
    "- `max_features`: Number of features to consider for splits (default = auto).\n",
    "- `max_depth`: Maximum depth of trees (default = None, meaning full depth).\n",
    "- `min_samples_split`: Minimum samples required to split a node.\n",
    "- `min_samples_leaf`: Minimum samples required at a leaf node.\n",
    "\n",
    "#### **Difference from Random Forest**\n",
    "- **Random Forest** selects the best split at each node, while Extra Trees splits randomly.\n",
    "- Extra Trees is computationally faster but may result in higher bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Isolation Forest**\n",
    "\n",
    "The **Isolation Forest** is an anomaly detection algorithm based on the idea of isolating data points. Unlike density-based or distance-based approaches, it focuses on isolating anomalies rather than profiling \"normal\" data points.\n",
    "\n",
    "#### **How Isolation Forest Works**\n",
    "1. **Random Partitioning**:\n",
    "   - The algorithm randomly selects a feature and a random split value between the feature’s minimum and maximum values.\n",
    "   - This process creates a \"tree\" structure where data points are progressively isolated by splits.\n",
    "\n",
    "2. **Isolation Depth**:\n",
    "   - Normal points require more splits to be isolated (deeper in the tree) because they tend to cluster together.\n",
    "   - Anomalies are isolated with fewer splits because they are far from other points or in low-density regions.\n",
    "\n",
    "3. **Ensemble of Trees**:\n",
    "   - Multiple trees are built to improve robustness.\n",
    "   - The average path length (depth of isolation) across all trees is used to score how anomalous a data point is.\n",
    "\n",
    "4. **Anomaly Scoring**:\n",
    "   - A score close to 1 indicates an anomaly.\n",
    "   - A score closer to 0 suggests a normal point.\n",
    "\n",
    "#### **Advantages**\n",
    "- **Efficient**:\n",
    "  - Works well with large datasets since it has a linear time complexity.\n",
    "- **No Assumptions**:\n",
    "  - Does not assume any distribution or cluster structure in the data.\n",
    "- **Handles High Dimensions**:\n",
    "  - Performs effectively even with high-dimensional data.\n",
    "\n",
    "#### **Disadvantages**\n",
    "- **Randomness**:\n",
    "  - Results can vary slightly due to random splits unless a seed is fixed.\n",
    "- **Limited Interpretability**:\n",
    "  - The process of isolation is less interpretable than other methods like distance-based clustering.\n",
    "\n",
    "#### **Common Use Cases**\n",
    "- **Fraud Detection**: Identifying unusual transactions in finance.\n",
    "- **Intrusion Detection**: Spotting anomalous behavior in network traffic.\n",
    "- **Manufacturing**: Detecting defective products or rare events.\n",
    "\n",
    "#### **Implementation in Python**\n",
    "\n",
    "Here’s an example using **Scikit-Learn**:\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "# Example dataset\n",
    "X = np.random.rand(100, 2)  # Normal data\n",
    "X_outliers = np.random.rand(10, 2) + 2  # Add anomalies\n",
    "X = np.vstack((X, X_outliers))\n",
    "\n",
    "# Initialize Isolation Forest\n",
    "isoforest = IsolationForest(n_estimators=100, contamination=0.1, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "isoforest.fit(X)\n",
    "\n",
    "# Predict anomalies\n",
    "predictions = isoforest.predict(X)  # -1 for anomalies, 1 for normal points\n",
    "anomaly_scores = isoforest.decision_function(X)\n",
    "\n",
    "# Results\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Anomaly Scores:\", anomaly_scores)\n",
    "```\n",
    "\n",
    "#### **Key Parameters**\n",
    "- **`n_estimators`**: Number of trees in the forest (default = 100).\n",
    "- **`max_samples`**: Number of samples to train each tree. Can be an integer or a fraction of the data.\n",
    "- **`contamination`**: The proportion of anomalies in the data (default = `auto` or a user-specified value).\n",
    "- **`max_features`**: Number of features to consider for each split.\n",
    "\n",
    "#### **Anomaly Score**\n",
    "- A decision function gives the anomaly score for each point.\n",
    "- The more negative the score, the more likely the point is an anomaly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unqiue\n",
      "(array([-1,  1]), array([ 2, 23], dtype=int64))\n",
      "Outliers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>water</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>lactose</th>\n",
       "      <th>ash</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animal</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SEAL</th>\n",
       "      <td>46.4</td>\n",
       "      <td>9.7</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOLPHIN</th>\n",
       "      <td>44.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>34.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         water  protein   fat  lactose   ash\n",
       "Animal                                      \n",
       "SEAL      46.4      9.7  42.0      0.0  0.85\n",
       "DOLPHIN   44.9     10.6  34.9      0.9  0.53"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\DAI.STUDENTSDC\\Desktop\\Machine Learning\\Data\\Data Sets\\milk.csv', index_col=0)\n",
    "\n",
    "iso = IsolationForest(\n",
    "    n_estimators=25,\n",
    "    contamination=0.05,\n",
    "    random_state=24\n",
    ")\n",
    "\n",
    "pred = iso.fit_predict(df)\n",
    "\n",
    "print('Unqiue')\n",
    "print(np.unique(pred, return_counts=True))\n",
    " \n",
    "\n",
    "print('Outliers')\n",
    "df[pred == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unqiue\n",
      "(array([-1,  1]), array([ 2000, 37999], dtype=int64))\n",
      "Outliers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>revenue</th>\n",
       "      <th>number_of_orders</th>\n",
       "      <th>recency_days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>most_recent_visit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-11-05</th>\n",
       "      <td>16677</td>\n",
       "      <td>220</td>\n",
       "      <td>5</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-15</th>\n",
       "      <td>2718</td>\n",
       "      <td>1633</td>\n",
       "      <td>16</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-11-25</th>\n",
       "      <td>27531</td>\n",
       "      <td>1804</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-11-19</th>\n",
       "      <td>18357</td>\n",
       "      <td>1561</td>\n",
       "      <td>18</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-21</th>\n",
       "      <td>2036</td>\n",
       "      <td>216</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-08-29</th>\n",
       "      <td>8581</td>\n",
       "      <td>381</td>\n",
       "      <td>4</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-09-29</th>\n",
       "      <td>34982</td>\n",
       "      <td>1998</td>\n",
       "      <td>19</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-16</th>\n",
       "      <td>25267</td>\n",
       "      <td>1464</td>\n",
       "      <td>16</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-25</th>\n",
       "      <td>5468</td>\n",
       "      <td>1576</td>\n",
       "      <td>15</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-08-06</th>\n",
       "      <td>32328</td>\n",
       "      <td>345</td>\n",
       "      <td>4</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   customer_id  revenue  number_of_orders  recency_days\n",
       "most_recent_visit                                                      \n",
       "2005-11-05               16677      220                 5           422\n",
       "2006-10-15                2718     1633                16            78\n",
       "2006-11-25               27531     1804                18            37\n",
       "2006-11-19               18357     1561                18            43\n",
       "2006-12-21                2036      216                 3            11\n",
       "...                        ...      ...               ...           ...\n",
       "2005-08-29                8581      381                 4           490\n",
       "2006-09-29               34982     1998                19            94\n",
       "2006-03-16               25267     1464                16           291\n",
       "2006-02-25                5468     1576                15           310\n",
       "2005-08-06               32328      345                 4           513\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\DAI.STUDENTSDC\\Desktop\\Machine Learning\\Data\\Cases\\Recency Frequency Monetary\\rfm_data_customer.csv', index_col=2)\n",
    "\n",
    "\n",
    "iso = IsolationForest(\n",
    "    n_estimators=25,\n",
    "    contamination=0.05,\n",
    "    random_state=24\n",
    ")\n",
    "pred = iso.fit_predict(df)\n",
    "\n",
    "\n",
    "print('Unqiue')\n",
    "print(np.unique(pred, return_counts=True))\n",
    " \n",
    "print('Outliers')\n",
    "df[pred == -1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
